{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9c/194n4ZZ51Rxi5teLq4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bekahwebb/bekahwebb.github.io/blob/main/Beautifulsoupcheetsheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "                        **Beautiful Soup Cheet Sheet**\n",
        "This cheat sheet covers the basics of Beautiful Soup, which should help you get started with web scraping and HTML parsing. You can refer to the Beautiful Soup documentation for more in-depth information and examples: Beautiful Soup Documentation."
      ],
      "metadata": {
        "id": "e5t-IL_NjXkt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiC0RsDAhTk4"
      },
      "outputs": [],
      "source": [
        "#import beautiful soup\n",
        "from bs4 import BeautifulSoup\n",
        "#Create a Soup Object:\n",
        "soup = BeautifulSoup(html, 'html.parser')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Navigating the HTML Tree"
      ],
      "metadata": {
        "id": "BJOcOFeJkKDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Find an element by tag name:\n",
        "soup.find('tag_name')\n",
        "#Find all elements by tag name:\n",
        "soup.find_all('tag_name')\n",
        "#Find the first element with a specific class:\n",
        "soup.find(class_='class_name')\n",
        "#Find all elements with a specific class:\n",
        "soup.find_all(class_='class_name')\n",
        "#Find elements by attribute:\n",
        "soup.find('tag_name', attrs={'attribute_name': 'attribute_value'})\n",
        "Find elements using CSS selectors:\n",
        "soup.select('selector')"
      ],
      "metadata": {
        "id": "qG_T5HXFjQ6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing Element Attributes and Data:"
      ],
      "metadata": {
        "id": "JC4mnXt1kX4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the text within an element:\n",
        "element.text\n",
        "#Get the value of an attribute:\n",
        "element['attribute_name']"
      ],
      "metadata": {
        "id": "nxqGyVbKkfps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traversing the HTML Tree:"
      ],
      "metadata": {
        "id": "Zf541jcLk1aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Access the parent element:\n",
        "element.parent\n",
        "#Access the next sibling element:\n",
        "element.next_sibling\n",
        "#Access the previous sibling element:\n",
        "element.previous_sibling\n",
        "#Access all child elements:\n",
        "element.contents"
      ],
      "metadata": {
        "id": "EldHaJCQk2rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modifying HTML:"
      ],
      "metadata": {
        "id": "kYmkGN1mlaVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the tag name:\n",
        "element.name = 'new_tag_name'\n",
        "#Modify an attribute:\n",
        "element['attribute_name'] = 'new_attribute_value'\n",
        "#Replace an element with new content:\n",
        "element.string = 'new_content'"
      ],
      "metadata": {
        "id": "NXMkPGLxlgp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing HTML:"
      ],
      "metadata": {
        "id": "J3jBnc6gl_4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parse an HTML string:\n",
        "soup = BeautifulSoup(html_string, 'html.parser')\n",
        "#Parse an HTML file:\n",
        "with open('file.html', 'r') as file:\n",
        "    soup = BeautifulSoup(file, 'html.parser')"
      ],
      "metadata": {
        "id": "gs7rf8lbmGP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Functions:"
      ],
      "metadata": {
        "id": "PosLEM_VmW6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if an element exists:\n",
        "if element is not None:\n",
        "    # Element exists\n",
        "#Check if an element has a specific class:\n",
        "if 'class_name' in element['class']:\n",
        "    # Element has the class\n",
        "# Remove extra whitespace from the headlines\n",
        "df['text'] = df['text'].str.strip()\n",
        "# Remove header row and reset index\n",
        "df = df[1:].reset_index(drop=True)\n",
        "# Rename columns\n",
        "df.columns = ['Column1', 'Column2', 'Column3']\n",
        "# Handle missing values\n",
        "df = df.dropna()\n",
        "# Convert data types\n",
        "df['Column3'] = df['Column3'].astype(float)\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "# Additional cleaning as needed\n",
        "# Print the cleaned DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "ZfTYiT0oma5p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}