---
layout: post
title:  "Campground Exploratory Data Analysis From the National Park Service."
author: Rebekah Webb
description: This is an exploration and anaysis on the camping data cost around the country.
image: /assets/images/camp_angels_land.png
---
# Introduction:
 I am going to do a deeper exploratory data analysis on my camp data than I did in my last camp blog post.  I mentioned in my last blog post that I want to examine potential correlations between some of the numeric data.  I am curious about what I will find in examining this data further.  I am trying to answer the questions about camping costs for National Parks across the country with the National Park Service Camping Data.  I want to know about outliers in my data, if my data is scale free, what the Cost of campgrounds is by Zip code regions, how does Utah's camping costs compare to surrounding states, and what the frequency of Park Codes is in my data? 

# Examining the suprise data results for top Camp Costs.
In my last blog post I shared a histogram with the results for the top camp costs.  When I first looked at the results of my camp_data.head() results I could see that there were some camp costs close to $100 was it's own surprise that camping could cost the same as a hotel.  When I did an overall data analysis of top costs, and I saw that the top cost was $1000 for two campgrounds, I thought I made an error in the code examining the the numerical values of my Cost column.

![cost_hist.png](/assets/images/cost_hist.png)

When I looked at the description of Camp Meadow, then I saw that it sleeps 140 people so it makes more since that it would be $1000 for one night of camping. I also searched for Camp Meadow on the internet, and saw that it's a rugged cabin for up to 140 people including amenities like a pool as well.  The top 7 in my bargraph are more 'glamping' campgrounds than camping.


# Checking to see if my data is scale free.
I converted my camp_data to an array so I could use logarithmic bins to show that the cost is scale free. Scale free data is observed in real life data, it is heavy tailed vs. normal distributions that have small tails. A Scale Free Network is where the distribution of links to nodes follows a power law. The power law means that the vast majority of nodes have very few connections, while a few important nodes (called Hubs) have a huge number of connections. 
``` 
import numpy as np
import matplotlib.pyplot as plt
camp_data = 10**np.random.normal(size=500)
_, bins = np.histogram(np.log10(camp_data + 1), bins='auto')
plt.hist(camp_data, bins=10**bins);
plt.gca().set_xscale("log")
plt.gca().set_yscale("log")
```

![log_log_bins.png](/assets/images/log_log_bins.png)

It should have a linear shape if it is scale free, looking at my logorithm bins histogram, my data looks nearly scale free.

# Checking for correllation and conversely inverse correlation

```
# Code to check for correlation
 camp_data.corr()

output
 Latitude	Longitude	Number Of Sites Reservable	Number Of Sites First Come First Serve	Cost
Latitude	1.000000	-0.071330	0.004874	-0.022480	-0.028497
Longitude	-0.071330	1.000000	-0.109048	-0.024575	0.080968
Number Of Sites Reservable	0.004874	-0.109048	1.000000	-0.018321	0.023920
Number Of Sites First Come First Serve	-0.022480	-0.024575	-0.018321	1.000000	-0.010007
Cost	-0.028497	0.080968	0.023920	-0.010007	1.000000
```
The correlation values and inverse correlation values are pretty much 0 so there isn't much correlation to observe.

# Looking at camp ground cost by the zip code region.
I wanted to group the cost of the campsite by the region where it is from using the first 2 digits of the zip codes of my data.

![zip_code_regions.png](/assets/images/zip_code_regions.png)

I made a dictionary to put the first 2 digits for each zip code in my data frame.
```
# Dictionary to store lists of zip codes for each region
region_zip_codes = {}
# Loop through each unique two-digit prefix in the Zip column
for prefix in camp_data['Zip'].apply(lambda x: str(x)[:2]).unique():
    # Filter the dataframe for the current region
    region_data = camp_data[camp_data['Zip'].apply(lambda x: str(x).startswith(prefix))]
    # Extract the zip codes for the current region
    zip_codes = region_data['Zip'].tolist()
    # Store the zip codes in the dictionary
    region_zip_codes["Region_" + prefix] = zip_codes
output
#truncated
 nan,
  nan,
...
 'Region_38': ['38462'],
 'Region_07': ['07825', '07881', '07832'],
 'Region_24': ['24526', '24523', '24091', '24248'],
 'Region_00': ['00000'],
 'Region_23': ['23651']}
 ```
# Creating a scatterplot of the cost of campsites by region
```
# Create a scatterplot
plt.figure(figsize=(12, 8))
sns.scatterplot(data=camp_data, x='Region', y='Cost', palette='viridis')
plt.title('Scatterplot of Cost by Region')
plt.xlabel('Region')
plt.ylabel('Cost')
plt.show()
```
![scatter_by_cost.png](/assets/images/scatter_by_cost.png)

Looking at the scatterplot results for cost by region, the results are not linear so I know there is not a strong relationship, or correlation between change in region and change in cost.  We can also see that the data by region is in the range between $0 and around $200. There are also points for the outliers by region that are in the range of around $400 to $1000.

# Creating a barplot of the cost of campsites by region highest to lowest

```
import seaborn as sns
import matplotlib.pyplot as plt
# Replace non-numeric values with NaN
camp_data['Cost'] = pd.to_numeric(camp_data['Cost'], errors='coerce')
# Fill NaN values with the mean cost
mean_cost = camp_data['Cost'].mean()
camp_data['Cost'].fillna(mean_cost, inplace=True)
# Order the regions by mean cost from highest to lowest
order = camp_data.groupby('Region')['Cost'].mean().sort_values(ascending=False).index
# Create a horizontal bar plot of mean Cost by Region
plt.figure(figsize=(12, 8))
sns.barplot(data=camp_data, y='Region', x='Cost', ci=None, orient='h', order=order)
plt.title('Mean Cost by Region (Highest to Lowest)')
plt.xlabel('Mean Cost')
plt.ylabel('Region')
plt.show()
```
![ordered_mean_cost_byreg.bar.png](/assets/images/ordered_mean_cost_byreg.bar.png)
The Midwest area in the US has the top average cost by region 55, eg Minnesota.  The Northeast area has the lowest cost by region 20, eg. Washington DC, and Virginia which makes since, there aren't a lot of National Parks in big cities.  Minnesota is one of the great lake states where you can imagine there are some great camping areas, and contrarily,  DC doesn't have many campgrounds or National Parks nearby.

# Looking at boxplots by region of Utah and surrounding neighbors

I mentioned in my first blog post that Utah is typically where my family goes camping.  I thought it would be fun to compare Utah with surrounding neighbor states to compare campground cost by region with BYU's state and bordering states.  I did boxplots for UT, ID, WY, CO, NM, AZ, and NV.

```
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# List of state codes for Utah and its neighboring Regions
utah_and_neighbors = ['84', '83', '82', '80', '87', '85', '88']
# Filter data for regions in Utah and its neighboring states
utah_and_neighbors_data = camp_data[camp_data['Region'].isin(utah_and_neighbors)]
# Set up a box plot
plt.figure(figsize=(12, 8))
sns.boxplot(x='Region', y='Cost', data=utah_and_neighbors_data)
plt.title('Box Plot of Cost by Region in Utah and Bordering States')
plt.xlabel('Region')
plt.ylabel('Cost')
plt.show()
```
![ut&neighbs_box.png](/assets/images/ut&neighbs_box.png)

Left to right the box plots are representing the Zip code regions of AZ, CO, NV, UT, WY, ID, and NM.  There are a few outliers in UT, WY, and ID.  ID has the highest cost for camping.  The order of highest campground cost to lowest is ID, UT, WY, CO, NM, AZ, and NV has missing values for the zip code so the campground cost is not represented in these results. UT, WY, and NM are positively skewed, and AZ, and ID are negatively skewed.  

On a personal note, I have been to the following National parks in these boxplots: AZ, the Grand Canyon, UT, Arches, Zion, Bryce Canyon, Capital Reef and the Canyonlands, and ID, Yellowstone.  I have enjoyed camping at most of these locations, the exceptions were Zion, the Grand Canyon, and Capital Reef where my family stayed in motels.

One of our favorite places to camp in UT is an open secret, so you are welcome for this info.  Castleton Rock is a bit off the beaten path for Arches National Park in Castle Valley, UT. It is a free campground and is world famous for it's photo graphic appeal and it's classic rock climbing routes. Some UT trivia that could be added to the capital building museum on things filmed in UT, is that the location was featured in a Chevy commercial in 1973.

![Castleton_rock.png](/assets/images/Castleton_rock.png)

# Examining the Park Codes Frequency

I wanted to see how frequently the Park Codes were used throughout my data.  I thought it would be cool to look at a word cloud to see the most frequently used Park Codes.

```
from wordcloud import WordCloud
park_code_text = ' '.join(camp_data['Park Code'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(park_code_text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()
```

![top.park_code_freq.word.png](/assets/images/top.park_code_freq.word.png)

Here's a breakdown of the largest 10 Park Codes and the frequency of their use, eg the total number of campgrounds by Park Code.

```
top_park_codes = camp_data['Park Code'].value_counts().nlargest(10)  # Top 10 Park Codes
plt.figure(figsize=(12, 6))
top_park_codes.plot(kind='bar')
plt.title('Top Park Codes by Frequency')
plt.xlabel('Park Code')
plt.ylabel('Frequency')
plt.show()
```
![top10_park.codes.png](/assets/images/top10_park.codes.png)

# Conclusion:

 It has been interesting to examine the National Park Service campground data.  I have really enjoyed the opportunity to go through this process of having a question that I wanted data to answer.  It's felt like I have been a detective decoding the National Park data by different column variables eg City or Zip to examine the costs of camping geographically.  I liked being suprised by the cost outliers of the campgrounds that were over $65 a night.  The Streamlit app was fun to design and interact with, check it out [here](https://campapp-7twimkm6la75fgzddaylsc.streamlit.app/)  It was part of my detective decoding, searching the data by different column names to find out more information about the different campgrounds in the National Parks across the nation.  I hope that the story that I told with campground data will help you in planning your next camping, or glamping trip.

 We live in a beautiful country, now go camp it.

![camp_adventure1.png](/assets/images/camp_adventure1.png)

